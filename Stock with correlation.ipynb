{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02494019-5d3b-4d36-8f07-7771786c913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55a3d37b-037b-4155-9c9a-a4283ffd4be5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "correlation={'C': ['S', 'NTRS', 'LYFT', 'LUV', 'LEA'],\n",
    " 'VTR': ['FOX', 'FRT', 'SPG', 'HST', 'S'],\n",
    " 'NWS': ['FCX', 'GS', 'EMR', 'PPG', 'JCI'],\n",
    " 'PG': ['WMT', 'PEP', 'MSFT', 'SO', 'PLD'],\n",
    " 'FRT': ['SPG', 'FOX', 'REG', 'RIVN', 'S'],\n",
    " 'CAT': ['PH', 'LIN', 'DE', 'EMR', 'ETN'],\n",
    " 'GM': ['RIVN', 'TROW', 'S', 'BAC', 'NTRS'],\n",
    " 'AMD': ['MSFT', 'NOW', 'AAPL', 'GOOGL', 'SHW'],\n",
    " 'SNOW': ['S', 'RIVN', 'SHOP', 'ECL', 'ETSY'],\n",
    " 'NRG': ['UNP', 'BHP', 'AXP', 'CSX', 'EMR'],\n",
    " 'CMS': ['XEL', 'WEC', 'AEP', 'PEG', 'ATO'],\n",
    " 'CSX': ['NSC', 'UNP', 'CNI', 'HON', 'PEG'],\n",
    " 'ESS': ['EQR', 'UDR', 'AVB', 'BAC', 'O'],\n",
    " 'SHOP': ['ETSY', 'EBAY', 'SQ', 'TROW', 'DOCU'],\n",
    " 'BIIB': ['AAL', 'BWA', 'WBA', 'NCLH', 'GILD'],\n",
    " 'S': ['LYFT', 'DIS', 'SNOW', 'TROW', 'TWLO'],\n",
    " 'VRTX': ['PGR', 'LMT', 'TDG', 'PCAR', 'MCD'],\n",
    " 'WBA': ['AAL', 'JBLU', 'NCLH', 'LYFT', 'CCL'],\n",
    " 'MO': ['PM', 'GD', 'REG', 'STZ', 'PRU'],\n",
    " 'LEA': ['NTRS', 'STT', 'FDX', 'GM', 'STZ'],\n",
    " 'DE': ['MS', 'LOW', 'CP', 'AMP', 'AAPL'],\n",
    " 'ITW': ['ROK', 'HD', 'MCD', 'TMUS', 'MSFT'],\n",
    " 'CP': ['DE', 'AAPL', 'RIO', 'LIN', 'LOW'],\n",
    " 'KMB': ['WEC', 'XEL', 'EQIX', 'CMS', 'APD'],\n",
    " 'ETN': ['PH', 'ORCL', 'AMP', 'LIN', 'PCAR'],\n",
    " 'KO': ['PEP', 'SO', 'MCD', 'SRE', 'DUK'],\n",
    " 'ETSY': ['NKE', 'TROW', 'SHOP', 'EL', 'EBAY'],\n",
    " 'FCX': ['NWS', 'BHP', 'JCI', 'AMP', 'MET'],\n",
    " 'ABBV': ['UNH', 'MMC', 'RJF', 'PGR', 'AMP'],\n",
    " 'NET': ['ZS', 'S', 'DDOG', 'TGT', 'RIVN'],\n",
    " 'ALL': ['JNJ', 'DUK', 'HON', 'CSX', 'TRV'],\n",
    " 'CSCO': ['CSX', 'PEG', 'V', 'JPM', 'ISRG'],\n",
    " 'EBAY': ['TROW', 'NKE', 'BBY', 'SHOP', 'ETSY'],\n",
    " 'EVRG': ['CMS', 'O', 'AEP', 'NI', 'WEC'],\n",
    " 'O': ['EVRG', 'AEP', 'CMS', 'WEC', 'XEL'],\n",
    " 'BBY': ['AMZN', 'CRM', 'NKE', 'NSC', 'TROW'],\n",
    " 'UPS': ['LOW', 'MS', 'DE', 'PLD', 'BLK'],\n",
    " 'STT': ['LEA', 'PRU', 'NTRS', 'SCHW', 'TXT'],\n",
    " 'DAL': ['UAL', 'RCL', 'LUV', 'BA', 'CCL'],\n",
    " 'WMT': ['PG', 'V', 'APD', 'MSFT', 'LIN'],\n",
    " 'SQ': ['PYPL', 'TWLO', 'DOCU', 'SHOP', 'ETSY'],\n",
    " 'GS': ['MS', 'RJF', 'AMP', 'MET', 'BLK'],\n",
    " 'NOC': ['LMT', 'ED', 'UNH', 'MCD', 'ATO'],\n",
    " 'PGR': ['MMC', 'MCD', 'LIN', 'UNH', 'COST'],\n",
    " 'RCL': ['DAL', 'BA', 'UAL', 'LUV', 'C'],\n",
    " 'TGT': ['NKE', 'EL', 'TROW', 'BLK', 'UPS'],\n",
    " 'FDX': ['STLA', 'LEA', 'PPG', 'BLK', 'META'],\n",
    " 'AMZN': ['CRM', 'ADBE', 'BBY', 'ABT', 'DLR'],\n",
    " 'GE': ['UBER', 'AAL', 'WBA', 'CRWD', 'SPG'],\n",
    " 'SRE': ['KO', 'SO', 'AEP', 'PEP', 'DUK'],\n",
    " 'LYFT': ['S', 'JBLU', 'RIVN', 'DIS', 'MMM'],\n",
    " 'CCL': ['NCLH', 'AAL', 'JBLU', 'WBA', 'TDS'],\n",
    " 'EQR': ['AVB', 'ESS', 'UDR', 'O', 'MAA'],\n",
    " 'BMY': ['ALB', 'DLTR', 'ABBV', 'DG', 'UPS'],\n",
    " 'PCAR': ['PH', 'ETN', 'TDG', 'LIN', 'LLY'],\n",
    " 'NTRS': ['BAC', 'SCHW', 'UDR', 'ESS', 'EL'],\n",
    " 'JBLU': ['LYFT', 'ALK', 'S', 'NCLH', 'WBA'],\n",
    " 'NOW': ['AMD', 'ADBE', 'MSFT', 'SHW', 'ABT'],\n",
    " 'SPG': ['FRT', 'FOX', 'REG', 'AIG', 'VTR'],\n",
    " 'DLR': ['AMZN', 'EQIX', 'ADBE', 'AMT', 'CMCSA'],\n",
    " 'LLY': ['NVO', 'PANW', 'ETN', 'PCAR', 'NVDA'],\n",
    " 'ABT': ['NSC', 'SHW', 'UNP', 'NEE', 'HD'],\n",
    " 'AAL': ['CCL', 'NCLH', 'WBA', 'S', 'LYFT'],\n",
    " 'AXP': ['DOV', 'EMR', 'MS', 'RIO', 'UNP'],\n",
    " 'ROST': ['V', 'JPM', 'HON', 'CSCO', 'ISRG'],\n",
    " 'TSLA': ['AAPL', 'UPS', 'LOW', 'GOOGL', 'AMD'],\n",
    " 'REGN': ['NVO', 'LLY', 'PANW', 'AAPL', 'AMP'],\n",
    " 'DG': ['NEE', 'SBAC', 'CCI', 'XEL', 'WEC'],\n",
    " 'NVDA': ['ETN', 'PANW', 'ORCL', 'NVO', 'LLY'],\n",
    " 'TRV': ['CB', 'RJF', 'KO', 'MCD', 'ALL'],\n",
    " 'ROK': ['ITW', 'DOV', 'BLK', 'ISRG', 'HD'],\n",
    " 'OGE': ['CNP', 'SRE', 'EXC', 'RTX', 'AEP'],\n",
    " 'UBER': ['META', 'ROST', 'NFLX', 'CRM', 'HMC'],\n",
    " 'WBD': ['S', 'LYFT', 'RIVN', 'LCID', 'SNOW'],\n",
    " 'TROW': ['EBAY', 'EL', 'NKE', 'RIVN', 'ETSY'],\n",
    " 'SHW': ['HD', 'ABT', 'NOW', 'DOV', 'ISRG'],\n",
    " 'SBAC': ['AMT', 'CCI', 'NEE', 'DG', 'ABT'],\n",
    " 'NI': ['ATO', 'ED', 'EVRG', 'AEP', 'CMS'],\n",
    " 'HMC': ['UBER', 'NWS', 'BWA', 'CRWD', 'IBM'],\n",
    " 'CVS': ['F', 'BMY', 'ZS', 'MRNA', 'BNTX'],\n",
    " 'NFLX': ['CRM', 'AMZN', 'ECL', 'ADBE', 'BBY'],\n",
    " 'MCD': ['PEP', 'MMC', 'KO', 'PGR', 'ITW'],\n",
    " 'UAL': ['DAL', 'CCL', 'NCLH', 'RCL', 'LUV'],\n",
    " 'EL': ['CCI', 'NKE', 'TROW', 'SBAC', 'TGT'],\n",
    " 'BAC': ['NTRS', 'SCHW', 'NSC', 'JPM', 'DEO'],\n",
    " 'PLD': ['HD', 'DOV', 'LOW', 'SHW', 'UNP'],\n",
    " 'PPG': ['BLK', 'SHW', 'DOV', 'ROK', 'HON'],\n",
    " 'NEM': ['CCI', 'SBAC', 'AMT', 'DG', 'NEE'],\n",
    " 'TMUS': ['ITW', 'HUM', 'UNH', 'PGR', 'MCD'],\n",
    " 'LOW': ['AAPL', 'HD', 'MSFT', 'PLD', 'DE'],\n",
    " 'MET': ['RJF', 'AMP', 'MS', 'GS', 'DE'],\n",
    " 'D': ['CCI', 'VZ', 'AMT', 'SBAC', 'ESS'],\n",
    " 'JCI': ['MS', 'GS', 'UPS', 'DE', 'DOV'],\n",
    " 'PH': ['ETN', 'CAT', 'PCAR', 'LIN', 'AMP'],\n",
    " 'NKLA': ['S', 'RIVN', 'SNOW', 'VZ', 'DOCU'],\n",
    " 'ADBE': ['CRM', 'NOW', 'AMZN', 'ISRG', 'SHW'],\n",
    " 'DOV': ['PLD', 'SHW', 'HD', 'ROK', 'UNP'],\n",
    " 'UDR': ['AVB', 'EQR', 'ESS', 'MAA', 'DEO'],\n",
    " 'SO': ['KO', 'PEP', 'SRE', 'PG', 'DUK'],\n",
    " 'BWA': ['HMC', 'FCX', 'MRNA', 'FOX', 'HST'],\n",
    " 'REG': ['WELL', 'AVB', 'FRT', 'AIG', 'CB'],\n",
    " 'CMI': ['ITW', 'RIO', 'CP', 'DE', 'ROK'],\n",
    " 'PRU': ['TXT', 'GD', 'SCHW', 'MET', 'RJF'],\n",
    " 'JNJ': ['DUK', 'UNH', 'CNI', 'MCD', 'CSX'],\n",
    " 'IBM': ['LLY', 'ETN', 'NVO', 'PCAR', 'XOM'],\n",
    " 'T': ['PNW', 'VZ', 'EVRG', 'O', 'HII'],\n",
    " 'RIO': ['CP', 'BHP', 'DE', 'CMI', 'DOV'],\n",
    " 'TTD': ['NOW', 'AMD', 'SHW', 'MSFT', 'AAPL'],\n",
    " 'STZ': ['NOC', 'JNJ', 'NI', 'TRV', 'GD'],\n",
    " 'LUV': ['MMM', 'LYFT', 'S', 'DAL', 'LNC'],\n",
    " 'BLK': ['SHW', 'ROK', 'DOV', 'HD', 'GOOGL'],\n",
    " 'MRNA': ['BNTX', 'TGT', 'NKE', 'TROW', 'EBAY'],\n",
    " 'TDS': ['CCL', 'NCLH', 'LYFT', 'JBLU', 'UAL'],\n",
    " 'ORCL': ['ETN', 'LIN', 'PH', 'MMC', 'AMP'],\n",
    " 'BA': ['RCL', 'C', 'DAL', 'UAL', 'PNW'],\n",
    " 'NCLH': ['CCL', 'AAL', 'JBLU', 'WBA', 'S'],\n",
    " 'HON': ['CSX', 'NSC', 'JPM', 'V', 'ISRG'],\n",
    " 'CCI': ['SBAC', 'AMT', 'EL', 'DG', 'NEE'],\n",
    " 'PEP': ['KO', 'MMC', 'MCD', 'SO', 'UNH'],\n",
    " 'LNC': ['S', 'LCID', 'MMM', 'RIVN', 'LUV'],\n",
    " 'CNP': ['OGE', 'EXC', 'GD', 'RTX', 'ED'],\n",
    " 'PEG': ['DUK', 'CSX', 'MCD', 'CMS', 'AEP'],\n",
    " 'LIN': ['MMC', 'MSFT', 'AAPL', 'COST', 'ETN'],\n",
    " 'DLTR': ['EXC', 'TRV', 'KO', 'ABBV', 'NOC'],\n",
    " 'PM': ['CB', 'GD', 'RJF', 'TRV', 'GS'],\n",
    " 'ATO': ['LMT', 'ED', 'NI', 'AEP', 'CMS'],\n",
    " 'COST': ['MMC', 'MSFT', 'AAPL', 'LIN', 'UNH'],\n",
    " 'DUK': ['PEG', 'KO', 'SO', 'JNJ', 'PLD'],\n",
    " 'MAA': ['PLD', 'DUK', 'UDR', 'DEO', 'DOV'],\n",
    " 'NEE': ['ABT', 'DG', 'XEL', 'WEC', 'NSC'],\n",
    " 'HUM': ['UNH', 'TMUS', 'JNJ', 'MCD', 'PEP'],\n",
    " 'APD': ['WMT', 'V', 'PG', 'EQIX', 'ABT'],\n",
    " 'ZS': ['DDOG', 'NET', 'NOW', 'CRWD', 'SHW'],\n",
    " 'TM': ['GOOGL', 'SHW', 'BLK', 'AMD', 'MSFT'],\n",
    " 'UNP': ['CSX', 'NSC', 'CNI', 'ABT', 'DOV'],\n",
    " 'VZ': ['INTC', 'ECL', 'D', 'CCI', 'AMT'],\n",
    " 'ISRG': ['SHW', 'HD', 'ADBE', 'ROK', 'V'],\n",
    " 'GD': ['CB', 'TRV', 'NOC', 'RJF', 'CI'],\n",
    " 'ECL': ['CRM', 'AMZN', 'NFLX', 'ADBE', 'AMT'],\n",
    " 'DOCU': ['PYPL', 'TWLO', 'SQ', 'RIVN', 'SNAP'],\n",
    " 'TJX': ['TDG', 'PGR', 'LIN', 'MMC', 'MCD'],\n",
    " 'EQIX': ['V', 'HD', 'SHW', 'ITW', 'APD'],\n",
    " 'CRWD': ['ZS', 'NOW', 'BLK', 'GOOGL', 'NWS'],\n",
    " 'META': ['ADBE', 'CRM', 'CMCSA', 'SAP', 'NFLX'],\n",
    " 'EXPE': ['GM', 'S', 'FOX', 'ESS', 'NET'],\n",
    " 'AAPL': ['MSFT', 'LOW', 'COST', 'LIN', 'MMC'],\n",
    " 'RJF': ['AMP', 'MET', 'MS', 'CB', 'DE'],\n",
    " 'LMT': ['NOC', 'ATO', 'MCD', 'ED', 'SRE'],\n",
    " 'CL': ['ITW', 'TMUS', 'EQIX', 'PG', 'SHW'],\n",
    " 'SNY': ['CP', 'LIN', 'PG', 'AAPL', 'MSFT'],\n",
    " 'TXT': ['PRU', 'STLA', 'GD', 'RJF', 'GS'],\n",
    " 'CB': ['TRV', 'RJF', 'MMC', 'AMP', 'UNH'],\n",
    " 'AIG': ['REG', 'PRU', 'XOM', 'TXT', 'IBM'],\n",
    " 'DDOG': ['ZS', 'NET', 'NOW', 'TSLA', 'ABT'],\n",
    " 'FOX': ['FRT', 'ALK', 'EQR', 'ESS', 'C'],\n",
    " 'CRM': ['ADBE', 'AMZN', 'NOW', 'ISRG', 'NFLX'],\n",
    " 'MMM': ['S', 'LUV', 'LYFT', 'RIVN', 'LNC'],\n",
    " 'ALB': ['MS', 'RJF', 'UPS', 'SCHW', 'GS'],\n",
    " 'PFE': ['MAA', 'DEO', 'EXC', 'DUK', 'NEE'],\n",
    " 'AMP': ['ETN', 'RJF', 'LIN', 'PH', 'DE'],\n",
    " 'V': ['WMT', 'EQIX', 'MCD', 'APD', 'ISRG'],\n",
    " 'ALK': ['JBLU', 'FOX', 'WBA', 'NCLH', 'CCL'],\n",
    " 'PYPL': ['TWLO', 'SQ', 'DOCU', 'RIVN', 'SHOP'],\n",
    " 'MSFT': ['AAPL', 'LIN', 'COST', 'AMD', 'NOW'],\n",
    " 'TDG': ['TJX', 'LIN', 'PGR', 'PH', 'MMC'],\n",
    " 'LCID': ['RIVN', 'LNC', 'S', 'EL', 'GM'],\n",
    " 'XEL': ['WEC', 'CMS', 'AEP', 'NEE', 'AMT'],\n",
    " 'AVB': ['EQR', 'UDR', 'ESS', 'MAA', 'WELL'],\n",
    " 'MMC': ['LIN', 'COST', 'PEP', 'UNH', 'MSFT'],\n",
    " 'GOOGL': ['MSFT', 'SHW', 'LOW', 'HD', 'AMD'],\n",
    " 'WELL': ['AVB', 'DUK', 'CB', 'PEG', 'AXP'],\n",
    " 'UNH': ['MMC', 'PEP', 'COST', 'ABBV', 'PGR'],\n",
    " 'SCHW': ['BAC', 'RJF', 'MS', 'GS', 'MET'],\n",
    " 'AMT': ['SBAC', 'CCI', 'XEL', 'WEC', 'CMS'],\n",
    " 'NKE': ['ABT', 'EL', 'TGT', 'SHW', 'TROW'],\n",
    " 'PANW': ['LLY', 'ETN', 'NVO', 'NVDA', 'COST'],\n",
    " 'CMCSA': ['ECL', 'BBY', 'DLR', 'META', 'AMZN'],\n",
    " 'AEP': ['CMS', 'WEC', 'XEL', 'ATO', 'PEG'],\n",
    " 'BNTX': ['MRNA', 'RIVN', 'TGT', 'S', 'NET'],\n",
    " 'ED': ['ATO', 'NI', 'NOC', 'LMT', 'SRE'],\n",
    " 'BKNG': ['STLA', 'PH', 'JPM', 'CAT', 'TDG'],\n",
    " 'DIS': ['S', 'PYPL', 'TWLO', 'SQ', 'LYFT'],\n",
    " 'NSC': ['CSX', 'UNP', 'ABT', 'HON', 'CNI'],\n",
    " 'CNI': ['CSX', 'UNP', 'NSC', 'HD', 'PLD'],\n",
    " 'MS': ['GS', 'DE', 'RJF', 'AMP', 'LOW'],\n",
    " 'EMR': ['DOV', 'CAT', 'MS', 'DE', 'AXP'],\n",
    " 'HII': ['STZ', 'NI', 'GD', 'ATO', 'NOC'],\n",
    " 'STLA': ['JPM', 'BKNG', 'CAT', 'PH', 'EMR'],\n",
    " 'GILD': ['REGN', 'XOM', 'TTD', 'CVS', 'NVO'],\n",
    " 'PNW': ['NI', 'ATO', 'EVRG', 'CMS', 'ED'],\n",
    " 'AES': ['NEE', 'CP', 'NSC', 'DG', 'ABT'],\n",
    " 'JPM': ['HON', 'ISRG', 'ITW', 'CSX', 'ROK'],\n",
    " 'RTX': ['EXC', 'TRV', 'AXP', 'RJF', 'KO'],\n",
    " 'NVO': ['LLY', 'PANW', 'ETN', 'NVDA', 'PCAR'],\n",
    " 'CI': ['UNH', 'ABBV', 'NOC', 'PGR', 'HUM'],\n",
    " 'SAP': ['META', 'NFLX', 'CRM', 'ADBE', 'ROST'],\n",
    " 'XOM': ['CVX', 'NVO', 'IBM', 'LLY', 'AIG'],\n",
    " 'INTC': ['VZ', 'ECL', 'NFLX', 'DLR', 'S'],\n",
    " 'CVX': ['EXC', 'ABBV', 'CB', 'RJF', 'XOM'],\n",
    " 'HD': ['SHW', 'LOW', 'PLD', 'ITW', 'ABT'],\n",
    " 'F': ['RIVN', 'FCX', 'JCI', 'ZS', 'NWS'],\n",
    " 'RIVN': ['PYPL', 'TWLO', 'TROW', 'LCID', 'DOCU'],\n",
    " 'TWLO': ['PYPL', 'SQ', 'DOCU', 'RIVN', 'S'],\n",
    " 'HST': ['TXT', 'PRU', 'CNP', 'RTX', 'CVX'],\n",
    " 'WEC': ['XEL', 'CMS', 'AEP', 'NEE', 'AMT'],\n",
    " 'BHP': ['RIO', 'CP', 'CMI', 'EMR', 'AXP'],\n",
    " 'EXC': ['KO', 'SRE', 'UNH', 'PEG', 'DUK'],\n",
    " 'DEO': ['NSC', 'DOV', 'CSX', 'PEG', 'MAA'],\n",
    " 'SNAP': ['S', 'SQ', 'DOCU', 'PYPL', 'TWLO']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31545de1-31d7-45d1-a9ca-2cd370228171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': ['S', 'NTRS', 'LYFT', 'LUV', 'LEA'],\n",
       " 'VTR': ['FOX', 'FRT', 'SPG', 'HST', 'S'],\n",
       " 'NWS': ['FCX', 'GS', 'EMR', 'PPG', 'JCI'],\n",
       " 'PG': ['WMT', 'PEP', 'MSFT', 'SO', 'PLD'],\n",
       " 'FRT': ['SPG', 'FOX', 'REG', 'RIVN', 'S'],\n",
       " 'CAT': ['PH', 'LIN', 'DE', 'EMR', 'ETN'],\n",
       " 'GM': ['RIVN', 'TROW', 'S', 'BAC', 'NTRS'],\n",
       " 'AMD': ['MSFT', 'NOW', 'AAPL', 'GOOGL', 'SHW'],\n",
       " 'SNOW': ['S', 'RIVN', 'SHOP', 'ECL', 'ETSY'],\n",
       " 'NRG': ['UNP', 'BHP', 'AXP', 'CSX', 'EMR'],\n",
       " 'CMS': ['XEL', 'WEC', 'AEP', 'PEG', 'ATO'],\n",
       " 'CSX': ['NSC', 'UNP', 'CNI', 'HON', 'PEG'],\n",
       " 'ESS': ['EQR', 'UDR', 'AVB', 'BAC', 'O'],\n",
       " 'SHOP': ['ETSY', 'EBAY', 'SQ', 'TROW', 'DOCU'],\n",
       " 'BIIB': ['AAL', 'BWA', 'WBA', 'NCLH', 'GILD'],\n",
       " 'S': ['LYFT', 'DIS', 'SNOW', 'TROW', 'TWLO'],\n",
       " 'VRTX': ['PGR', 'LMT', 'TDG', 'PCAR', 'MCD'],\n",
       " 'WBA': ['AAL', 'JBLU', 'NCLH', 'LYFT', 'CCL'],\n",
       " 'MO': ['PM', 'GD', 'REG', 'STZ', 'PRU'],\n",
       " 'LEA': ['NTRS', 'STT', 'FDX', 'GM', 'STZ'],\n",
       " 'DE': ['MS', 'LOW', 'CP', 'AMP', 'AAPL'],\n",
       " 'ITW': ['ROK', 'HD', 'MCD', 'TMUS', 'MSFT'],\n",
       " 'CP': ['DE', 'AAPL', 'RIO', 'LIN', 'LOW'],\n",
       " 'KMB': ['WEC', 'XEL', 'EQIX', 'CMS', 'APD'],\n",
       " 'ETN': ['PH', 'ORCL', 'AMP', 'LIN', 'PCAR'],\n",
       " 'KO': ['PEP', 'SO', 'MCD', 'SRE', 'DUK'],\n",
       " 'ETSY': ['NKE', 'TROW', 'SHOP', 'EL', 'EBAY'],\n",
       " 'FCX': ['NWS', 'BHP', 'JCI', 'AMP', 'MET'],\n",
       " 'ABBV': ['UNH', 'MMC', 'RJF', 'PGR', 'AMP'],\n",
       " 'NET': ['ZS', 'S', 'DDOG', 'TGT', 'RIVN'],\n",
       " 'ALL': ['JNJ', 'DUK', 'HON', 'CSX', 'TRV'],\n",
       " 'CSCO': ['CSX', 'PEG', 'V', 'JPM', 'ISRG'],\n",
       " 'EBAY': ['TROW', 'NKE', 'BBY', 'SHOP', 'ETSY'],\n",
       " 'EVRG': ['CMS', 'O', 'AEP', 'NI', 'WEC'],\n",
       " 'O': ['EVRG', 'AEP', 'CMS', 'WEC', 'XEL'],\n",
       " 'BBY': ['AMZN', 'CRM', 'NKE', 'NSC', 'TROW'],\n",
       " 'UPS': ['LOW', 'MS', 'DE', 'PLD', 'BLK'],\n",
       " 'STT': ['LEA', 'PRU', 'NTRS', 'SCHW', 'TXT'],\n",
       " 'DAL': ['UAL', 'RCL', 'LUV', 'BA', 'CCL'],\n",
       " 'WMT': ['PG', 'V', 'APD', 'MSFT', 'LIN'],\n",
       " 'SQ': ['PYPL', 'TWLO', 'DOCU', 'SHOP', 'ETSY'],\n",
       " 'GS': ['MS', 'RJF', 'AMP', 'MET', 'BLK'],\n",
       " 'NOC': ['LMT', 'ED', 'UNH', 'MCD', 'ATO'],\n",
       " 'PGR': ['MMC', 'MCD', 'LIN', 'UNH', 'COST'],\n",
       " 'RCL': ['DAL', 'BA', 'UAL', 'LUV', 'C'],\n",
       " 'TGT': ['NKE', 'EL', 'TROW', 'BLK', 'UPS'],\n",
       " 'FDX': ['STLA', 'LEA', 'PPG', 'BLK', 'META'],\n",
       " 'AMZN': ['CRM', 'ADBE', 'BBY', 'ABT', 'DLR'],\n",
       " 'GE': ['UBER', 'AAL', 'WBA', 'CRWD', 'SPG'],\n",
       " 'SRE': ['KO', 'SO', 'AEP', 'PEP', 'DUK'],\n",
       " 'LYFT': ['S', 'JBLU', 'RIVN', 'DIS', 'MMM'],\n",
       " 'CCL': ['NCLH', 'AAL', 'JBLU', 'WBA', 'TDS'],\n",
       " 'EQR': ['AVB', 'ESS', 'UDR', 'O', 'MAA'],\n",
       " 'BMY': ['ALB', 'DLTR', 'ABBV', 'DG', 'UPS'],\n",
       " 'PCAR': ['PH', 'ETN', 'TDG', 'LIN', 'LLY'],\n",
       " 'NTRS': ['BAC', 'SCHW', 'UDR', 'ESS', 'EL'],\n",
       " 'JBLU': ['LYFT', 'ALK', 'S', 'NCLH', 'WBA'],\n",
       " 'NOW': ['AMD', 'ADBE', 'MSFT', 'SHW', 'ABT'],\n",
       " 'SPG': ['FRT', 'FOX', 'REG', 'AIG', 'VTR'],\n",
       " 'DLR': ['AMZN', 'EQIX', 'ADBE', 'AMT', 'CMCSA'],\n",
       " 'LLY': ['NVO', 'PANW', 'ETN', 'PCAR', 'NVDA'],\n",
       " 'ABT': ['NSC', 'SHW', 'UNP', 'NEE', 'HD'],\n",
       " 'AAL': ['CCL', 'NCLH', 'WBA', 'S', 'LYFT'],\n",
       " 'AXP': ['DOV', 'EMR', 'MS', 'RIO', 'UNP'],\n",
       " 'ROST': ['V', 'JPM', 'HON', 'CSCO', 'ISRG'],\n",
       " 'TSLA': ['AAPL', 'UPS', 'LOW', 'GOOGL', 'AMD'],\n",
       " 'REGN': ['NVO', 'LLY', 'PANW', 'AAPL', 'AMP'],\n",
       " 'DG': ['NEE', 'SBAC', 'CCI', 'XEL', 'WEC'],\n",
       " 'NVDA': ['ETN', 'PANW', 'ORCL', 'NVO', 'LLY'],\n",
       " 'TRV': ['CB', 'RJF', 'KO', 'MCD', 'ALL'],\n",
       " 'ROK': ['ITW', 'DOV', 'BLK', 'ISRG', 'HD'],\n",
       " 'OGE': ['CNP', 'SRE', 'EXC', 'RTX', 'AEP'],\n",
       " 'UBER': ['META', 'ROST', 'NFLX', 'CRM', 'HMC'],\n",
       " 'WBD': ['S', 'LYFT', 'RIVN', 'LCID', 'SNOW'],\n",
       " 'TROW': ['EBAY', 'EL', 'NKE', 'RIVN', 'ETSY'],\n",
       " 'SHW': ['HD', 'ABT', 'NOW', 'DOV', 'ISRG'],\n",
       " 'SBAC': ['AMT', 'CCI', 'NEE', 'DG', 'ABT'],\n",
       " 'NI': ['ATO', 'ED', 'EVRG', 'AEP', 'CMS'],\n",
       " 'HMC': ['UBER', 'NWS', 'BWA', 'CRWD', 'IBM'],\n",
       " 'CVS': ['F', 'BMY', 'ZS', 'MRNA', 'BNTX'],\n",
       " 'NFLX': ['CRM', 'AMZN', 'ECL', 'ADBE', 'BBY'],\n",
       " 'MCD': ['PEP', 'MMC', 'KO', 'PGR', 'ITW'],\n",
       " 'UAL': ['DAL', 'CCL', 'NCLH', 'RCL', 'LUV'],\n",
       " 'EL': ['CCI', 'NKE', 'TROW', 'SBAC', 'TGT'],\n",
       " 'BAC': ['NTRS', 'SCHW', 'NSC', 'JPM', 'DEO'],\n",
       " 'PLD': ['HD', 'DOV', 'LOW', 'SHW', 'UNP'],\n",
       " 'PPG': ['BLK', 'SHW', 'DOV', 'ROK', 'HON'],\n",
       " 'NEM': ['CCI', 'SBAC', 'AMT', 'DG', 'NEE'],\n",
       " 'TMUS': ['ITW', 'HUM', 'UNH', 'PGR', 'MCD'],\n",
       " 'LOW': ['AAPL', 'HD', 'MSFT', 'PLD', 'DE'],\n",
       " 'MET': ['RJF', 'AMP', 'MS', 'GS', 'DE'],\n",
       " 'D': ['CCI', 'VZ', 'AMT', 'SBAC', 'ESS'],\n",
       " 'JCI': ['MS', 'GS', 'UPS', 'DE', 'DOV'],\n",
       " 'PH': ['ETN', 'CAT', 'PCAR', 'LIN', 'AMP'],\n",
       " 'NKLA': ['S', 'RIVN', 'SNOW', 'VZ', 'DOCU'],\n",
       " 'ADBE': ['CRM', 'NOW', 'AMZN', 'ISRG', 'SHW'],\n",
       " 'DOV': ['PLD', 'SHW', 'HD', 'ROK', 'UNP'],\n",
       " 'UDR': ['AVB', 'EQR', 'ESS', 'MAA', 'DEO'],\n",
       " 'SO': ['KO', 'PEP', 'SRE', 'PG', 'DUK'],\n",
       " 'BWA': ['HMC', 'FCX', 'MRNA', 'FOX', 'HST'],\n",
       " 'REG': ['WELL', 'AVB', 'FRT', 'AIG', 'CB'],\n",
       " 'CMI': ['ITW', 'RIO', 'CP', 'DE', 'ROK'],\n",
       " 'PRU': ['TXT', 'GD', 'SCHW', 'MET', 'RJF'],\n",
       " 'JNJ': ['DUK', 'UNH', 'CNI', 'MCD', 'CSX'],\n",
       " 'IBM': ['LLY', 'ETN', 'NVO', 'PCAR', 'XOM'],\n",
       " 'T': ['PNW', 'VZ', 'EVRG', 'O', 'HII'],\n",
       " 'RIO': ['CP', 'BHP', 'DE', 'CMI', 'DOV'],\n",
       " 'TTD': ['NOW', 'AMD', 'SHW', 'MSFT', 'AAPL'],\n",
       " 'STZ': ['NOC', 'JNJ', 'NI', 'TRV', 'GD'],\n",
       " 'LUV': ['MMM', 'LYFT', 'S', 'DAL', 'LNC'],\n",
       " 'BLK': ['SHW', 'ROK', 'DOV', 'HD', 'GOOGL'],\n",
       " 'MRNA': ['BNTX', 'TGT', 'NKE', 'TROW', 'EBAY'],\n",
       " 'TDS': ['CCL', 'NCLH', 'LYFT', 'JBLU', 'UAL'],\n",
       " 'ORCL': ['ETN', 'LIN', 'PH', 'MMC', 'AMP'],\n",
       " 'BA': ['RCL', 'C', 'DAL', 'UAL', 'PNW'],\n",
       " 'NCLH': ['CCL', 'AAL', 'JBLU', 'WBA', 'S'],\n",
       " 'HON': ['CSX', 'NSC', 'JPM', 'V', 'ISRG'],\n",
       " 'CCI': ['SBAC', 'AMT', 'EL', 'DG', 'NEE'],\n",
       " 'PEP': ['KO', 'MMC', 'MCD', 'SO', 'UNH'],\n",
       " 'LNC': ['S', 'LCID', 'MMM', 'RIVN', 'LUV'],\n",
       " 'CNP': ['OGE', 'EXC', 'GD', 'RTX', 'ED'],\n",
       " 'PEG': ['DUK', 'CSX', 'MCD', 'CMS', 'AEP'],\n",
       " 'LIN': ['MMC', 'MSFT', 'AAPL', 'COST', 'ETN'],\n",
       " 'DLTR': ['EXC', 'TRV', 'KO', 'ABBV', 'NOC'],\n",
       " 'PM': ['CB', 'GD', 'RJF', 'TRV', 'GS'],\n",
       " 'ATO': ['LMT', 'ED', 'NI', 'AEP', 'CMS'],\n",
       " 'COST': ['MMC', 'MSFT', 'AAPL', 'LIN', 'UNH'],\n",
       " 'DUK': ['PEG', 'KO', 'SO', 'JNJ', 'PLD'],\n",
       " 'MAA': ['PLD', 'DUK', 'UDR', 'DEO', 'DOV'],\n",
       " 'NEE': ['ABT', 'DG', 'XEL', 'WEC', 'NSC'],\n",
       " 'HUM': ['UNH', 'TMUS', 'JNJ', 'MCD', 'PEP'],\n",
       " 'APD': ['WMT', 'V', 'PG', 'EQIX', 'ABT'],\n",
       " 'ZS': ['DDOG', 'NET', 'NOW', 'CRWD', 'SHW'],\n",
       " 'TM': ['GOOGL', 'SHW', 'BLK', 'AMD', 'MSFT'],\n",
       " 'UNP': ['CSX', 'NSC', 'CNI', 'ABT', 'DOV'],\n",
       " 'VZ': ['INTC', 'ECL', 'D', 'CCI', 'AMT'],\n",
       " 'ISRG': ['SHW', 'HD', 'ADBE', 'ROK', 'V'],\n",
       " 'GD': ['CB', 'TRV', 'NOC', 'RJF', 'CI'],\n",
       " 'ECL': ['CRM', 'AMZN', 'NFLX', 'ADBE', 'AMT'],\n",
       " 'DOCU': ['PYPL', 'TWLO', 'SQ', 'RIVN', 'SNAP'],\n",
       " 'TJX': ['TDG', 'PGR', 'LIN', 'MMC', 'MCD'],\n",
       " 'EQIX': ['V', 'HD', 'SHW', 'ITW', 'APD'],\n",
       " 'CRWD': ['ZS', 'NOW', 'BLK', 'GOOGL', 'NWS'],\n",
       " 'META': ['ADBE', 'CRM', 'CMCSA', 'SAP', 'NFLX'],\n",
       " 'EXPE': ['GM', 'S', 'FOX', 'ESS', 'NET'],\n",
       " 'AAPL': ['MSFT', 'LOW', 'COST', 'LIN', 'MMC'],\n",
       " 'RJF': ['AMP', 'MET', 'MS', 'CB', 'DE'],\n",
       " 'LMT': ['NOC', 'ATO', 'MCD', 'ED', 'SRE'],\n",
       " 'CL': ['ITW', 'TMUS', 'EQIX', 'PG', 'SHW'],\n",
       " 'SNY': ['CP', 'LIN', 'PG', 'AAPL', 'MSFT'],\n",
       " 'TXT': ['PRU', 'STLA', 'GD', 'RJF', 'GS'],\n",
       " 'CB': ['TRV', 'RJF', 'MMC', 'AMP', 'UNH'],\n",
       " 'AIG': ['REG', 'PRU', 'XOM', 'TXT', 'IBM'],\n",
       " 'DDOG': ['ZS', 'NET', 'NOW', 'TSLA', 'ABT'],\n",
       " 'FOX': ['FRT', 'ALK', 'EQR', 'ESS', 'C'],\n",
       " 'CRM': ['ADBE', 'AMZN', 'NOW', 'ISRG', 'NFLX'],\n",
       " 'MMM': ['S', 'LUV', 'LYFT', 'RIVN', 'LNC'],\n",
       " 'ALB': ['MS', 'RJF', 'UPS', 'SCHW', 'GS'],\n",
       " 'PFE': ['MAA', 'DEO', 'EXC', 'DUK', 'NEE'],\n",
       " 'AMP': ['ETN', 'RJF', 'LIN', 'PH', 'DE'],\n",
       " 'V': ['WMT', 'EQIX', 'MCD', 'APD', 'ISRG'],\n",
       " 'ALK': ['JBLU', 'FOX', 'WBA', 'NCLH', 'CCL'],\n",
       " 'PYPL': ['TWLO', 'SQ', 'DOCU', 'RIVN', 'SHOP'],\n",
       " 'MSFT': ['AAPL', 'LIN', 'COST', 'AMD', 'NOW'],\n",
       " 'TDG': ['TJX', 'LIN', 'PGR', 'PH', 'MMC'],\n",
       " 'LCID': ['RIVN', 'LNC', 'S', 'EL', 'GM'],\n",
       " 'XEL': ['WEC', 'CMS', 'AEP', 'NEE', 'AMT'],\n",
       " 'AVB': ['EQR', 'UDR', 'ESS', 'MAA', 'WELL'],\n",
       " 'MMC': ['LIN', 'COST', 'PEP', 'UNH', 'MSFT'],\n",
       " 'GOOGL': ['MSFT', 'SHW', 'LOW', 'HD', 'AMD'],\n",
       " 'WELL': ['AVB', 'DUK', 'CB', 'PEG', 'AXP'],\n",
       " 'UNH': ['MMC', 'PEP', 'COST', 'ABBV', 'PGR'],\n",
       " 'SCHW': ['BAC', 'RJF', 'MS', 'GS', 'MET'],\n",
       " 'AMT': ['SBAC', 'CCI', 'XEL', 'WEC', 'CMS'],\n",
       " 'NKE': ['ABT', 'EL', 'TGT', 'SHW', 'TROW'],\n",
       " 'PANW': ['LLY', 'ETN', 'NVO', 'NVDA', 'COST'],\n",
       " 'CMCSA': ['ECL', 'BBY', 'DLR', 'META', 'AMZN'],\n",
       " 'AEP': ['CMS', 'WEC', 'XEL', 'ATO', 'PEG'],\n",
       " 'BNTX': ['MRNA', 'RIVN', 'TGT', 'S', 'NET'],\n",
       " 'ED': ['ATO', 'NI', 'NOC', 'LMT', 'SRE'],\n",
       " 'BKNG': ['STLA', 'PH', 'JPM', 'CAT', 'TDG'],\n",
       " 'DIS': ['S', 'PYPL', 'TWLO', 'SQ', 'LYFT'],\n",
       " 'NSC': ['CSX', 'UNP', 'ABT', 'HON', 'CNI'],\n",
       " 'CNI': ['CSX', 'UNP', 'NSC', 'HD', 'PLD'],\n",
       " 'MS': ['GS', 'DE', 'RJF', 'AMP', 'LOW'],\n",
       " 'EMR': ['DOV', 'CAT', 'MS', 'DE', 'AXP'],\n",
       " 'HII': ['STZ', 'NI', 'GD', 'ATO', 'NOC'],\n",
       " 'STLA': ['JPM', 'BKNG', 'CAT', 'PH', 'EMR'],\n",
       " 'GILD': ['REGN', 'XOM', 'TTD', 'CVS', 'NVO'],\n",
       " 'PNW': ['NI', 'ATO', 'EVRG', 'CMS', 'ED'],\n",
       " 'AES': ['NEE', 'CP', 'NSC', 'DG', 'ABT'],\n",
       " 'JPM': ['HON', 'ISRG', 'ITW', 'CSX', 'ROK'],\n",
       " 'RTX': ['EXC', 'TRV', 'AXP', 'RJF', 'KO'],\n",
       " 'NVO': ['LLY', 'PANW', 'ETN', 'NVDA', 'PCAR'],\n",
       " 'CI': ['UNH', 'ABBV', 'NOC', 'PGR', 'HUM'],\n",
       " 'SAP': ['META', 'NFLX', 'CRM', 'ADBE', 'ROST'],\n",
       " 'XOM': ['CVX', 'NVO', 'IBM', 'LLY', 'AIG'],\n",
       " 'INTC': ['VZ', 'ECL', 'NFLX', 'DLR', 'S'],\n",
       " 'CVX': ['EXC', 'ABBV', 'CB', 'RJF', 'XOM'],\n",
       " 'HD': ['SHW', 'LOW', 'PLD', 'ITW', 'ABT'],\n",
       " 'F': ['RIVN', 'FCX', 'JCI', 'ZS', 'NWS'],\n",
       " 'RIVN': ['PYPL', 'TWLO', 'TROW', 'LCID', 'DOCU'],\n",
       " 'TWLO': ['PYPL', 'SQ', 'DOCU', 'RIVN', 'S'],\n",
       " 'HST': ['TXT', 'PRU', 'CNP', 'RTX', 'CVX'],\n",
       " 'WEC': ['XEL', 'CMS', 'AEP', 'NEE', 'AMT'],\n",
       " 'BHP': ['RIO', 'CP', 'CMI', 'EMR', 'AXP'],\n",
       " 'EXC': ['KO', 'SRE', 'UNH', 'PEG', 'DUK'],\n",
       " 'DEO': ['NSC', 'DOV', 'CSX', 'PEG', 'MAA'],\n",
       " 'SNAP': ['S', 'SQ', 'DOCU', 'PYPL', 'TWLO']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc151973-f00f-4288-9dfd-13b5f3b6d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05039db4-7e42-4eda-afee-3b971f75fb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "def download_stock_data(main_company, correlation):\n",
    "    companies = [main_company] + correlation.get(main_company, [])\n",
    "    stock_data = {}\n",
    "\n",
    "    start_date = \"2012-01-01\"\n",
    "    end_date = pd.to_datetime(\"today\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    for company in companies:\n",
    "        stock_data[company] = yf.download(company, start=start_date, end=end_date)[[\"Open\", \"High\", \"Low\", \"Close\"]]\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "main_company = \"TSLA\"\n",
    "df = download_stock_data(main_company, correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "780e4676-89b1-4eed-b38e-6d6c7684e28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TSLA': Price             Open        High         Low       Close\n",
       " Ticker            TSLA        TSLA        TSLA        TSLA\n",
       " Date                                                      \n",
       " 2012-01-03    1.929333    1.966667    1.843333    1.872000\n",
       " 2012-01-04    1.880667    1.911333    1.833333    1.847333\n",
       " 2012-01-05    1.850667    1.862000    1.790000    1.808000\n",
       " 2012-01-06    1.813333    1.852667    1.760667    1.794000\n",
       " 2012-01-09    1.800000    1.832667    1.741333    1.816667\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12  247.220001  251.839996  241.100006  248.089996\n",
       " 2025-03-13  248.130005  248.289993  232.600006  240.679993\n",
       " 2025-03-14  247.309998  251.580002  240.729996  249.979996\n",
       " 2025-03-17  245.059998  245.399994  232.800003  238.009995\n",
       " 2025-03-18  228.160004  230.100006  222.279999  225.309998\n",
       " \n",
       " [3321 rows x 4 columns],\n",
       " 'AAPL': Price             Open        High         Low       Close\n",
       " Ticker            AAPL        AAPL        AAPL        AAPL\n",
       " Date                                                      \n",
       " 2012-01-03   12.320317   12.413607   12.308279   12.375387\n",
       " 2012-01-04   12.338373   12.479211   12.316706   12.441895\n",
       " 2012-01-05   12.487337   12.595673   12.418723   12.580025\n",
       " 2012-01-06   12.632391   12.722070   12.615840   12.711537\n",
       " 2012-01-09   12.804826   12.872536   12.679937   12.691373\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12  220.139999  221.750000  214.910004  216.979996\n",
       " 2025-03-13  215.949997  216.839996  208.419998  209.679993\n",
       " 2025-03-14  211.250000  213.949997  209.580002  213.490005\n",
       " 2025-03-17  213.309998  215.220001  209.970001  214.000000\n",
       " 2025-03-18  214.160004  215.149994  211.490005  212.690002\n",
       " \n",
       " [3321 rows x 4 columns],\n",
       " 'UPS': Price             Open        High         Low       Close\n",
       " Ticker             UPS         UPS         UPS         UPS\n",
       " Date                                                      \n",
       " 2012-01-03   48.284520   48.878206   48.167086   48.382381\n",
       " 2012-01-04   48.232334   48.519394   47.964845   48.173615\n",
       " 2012-01-05   47.925696   47.951793   47.071046   47.703880\n",
       " 2012-01-06   47.710409   48.238861   47.658220   47.938755\n",
       " 2012-01-09   47.788680   47.951781   47.514671   47.919159\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12  115.900002  116.070000  114.949997  115.260002\n",
       " 2025-03-13  115.769997  117.470001  114.959999  115.230003\n",
       " 2025-03-14  115.790001  116.919998  115.089996  116.760002\n",
       " 2025-03-17  117.000000  118.779999  116.919998  118.059998\n",
       " 2025-03-18  118.040001  119.000000  117.860001  118.860001\n",
       " \n",
       " [3321 rows x 4 columns],\n",
       " 'LOW': Price             Open        High         Low       Close\n",
       " Ticker             LOW         LOW         LOW         LOW\n",
       " Date                                                      \n",
       " 2012-01-03   20.236957   20.512987   20.063452   20.126545\n",
       " 2012-01-04   20.126537   20.907308   20.079217   20.875761\n",
       " 2012-01-05   20.789017   20.852109   20.489326   20.796904\n",
       " 2012-01-06   20.789011   20.867875   20.576073   20.773237\n",
       " 2012-01-09   20.804790   20.804790   20.473554   20.583967\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12  233.009995  234.750000  226.399994  228.330002\n",
       " 2025-03-13  227.729996  228.360001  220.169998  222.660004\n",
       " 2025-03-14  224.339996  224.759995  221.020004  224.440002\n",
       " 2025-03-17  225.000000  226.630005  223.399994  225.850006\n",
       " 2025-03-18  224.869995  225.580002  222.570007  222.949997\n",
       " \n",
       " [3321 rows x 4 columns],\n",
       " 'GOOGL': Price             Open        High         Low       Close\n",
       " Ticker           GOOGL       GOOGL       GOOGL       GOOGL\n",
       " Date                                                      \n",
       " 2012-01-03   16.262092   16.640911   16.247896   16.572668\n",
       " 2012-01-04   16.563204   16.693214   16.453370   16.644150\n",
       " 2012-01-05   16.490977   16.536803   16.344031   16.413269\n",
       " 2012-01-06   16.416756   16.437927   16.183636   16.189365\n",
       " 2012-01-09   16.101696   16.114149   15.472323   15.502957\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12  166.580002  167.639999  163.529999  167.110001\n",
       " 2025-03-13  166.039993  166.130005  162.110001  162.759995\n",
       " 2025-03-14  163.270004  166.490005  162.449997  165.490005\n",
       " 2025-03-17  165.029999  166.300003  163.669998  164.289993\n",
       " 2025-03-18  163.679993  164.250000  156.720001  160.669998\n",
       " \n",
       " [3321 rows x 4 columns],\n",
       " 'AMD': Price             Open        High         Low       Close\n",
       " Ticker             AMD         AMD         AMD         AMD\n",
       " Date                                                      \n",
       " 2012-01-03    5.530000    5.590000    5.440000    5.480000\n",
       " 2012-01-04    5.470000    5.490000    5.410000    5.460000\n",
       " 2012-01-05    5.450000    5.570000    5.350000    5.460000\n",
       " 2012-01-06    5.440000    5.520000    5.390000    5.430000\n",
       " 2012-01-09    5.420000    5.600000    5.380000    5.590000\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12   99.050003  101.720001   98.169998  100.790001\n",
       " 2025-03-13   99.720001  100.070000   97.269997   98.110001\n",
       " 2025-03-14   99.639999  101.220001   99.580002  100.970001\n",
       " 2025-03-17  102.599998  106.150002  102.599998  104.589996\n",
       " 2025-03-18  103.849998  104.550003  102.970001  103.510002\n",
       " \n",
       " [3321 rows x 4 columns]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8663af1-5d58-4370-8a1f-ad1eccc0a73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL', 'UPS', 'LOW', 'GOOGL', 'AMD']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation.get(\"TSLA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b1ca6e3-2e4d-4108-a9ca-f66aa042ed1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TSLA': Price             Open        High         Low       Close\n",
       " Ticker            TSLA        TSLA        TSLA        TSLA\n",
       " Date                                                      \n",
       " 2012-01-03    1.929333    1.966667    1.843333    1.872000\n",
       " 2012-01-04    1.880667    1.911333    1.833333    1.847333\n",
       " 2012-01-05    1.850667    1.862000    1.790000    1.808000\n",
       " 2012-01-06    1.813333    1.852667    1.760667    1.794000\n",
       " 2012-01-09    1.800000    1.832667    1.741333    1.816667\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12  247.220001  251.839996  241.100006  248.089996\n",
       " 2025-03-13  248.130005  248.289993  232.600006  240.679993\n",
       " 2025-03-14  247.309998  251.580002  240.729996  249.979996\n",
       " 2025-03-17  245.059998  245.399994  232.800003  238.009995\n",
       " 2025-03-18  228.160004  230.100006  222.279999  225.309998\n",
       " \n",
       " [3321 rows x 4 columns],\n",
       " 'AAPL': Price             Open        High         Low       Close\n",
       " Ticker            AAPL        AAPL        AAPL        AAPL\n",
       " Date                                                      \n",
       " 2012-01-03   12.320317   12.413607   12.308279   12.375387\n",
       " 2012-01-04   12.338373   12.479211   12.316706   12.441895\n",
       " 2012-01-05   12.487337   12.595673   12.418723   12.580025\n",
       " 2012-01-06   12.632391   12.722070   12.615840   12.711537\n",
       " 2012-01-09   12.804826   12.872536   12.679937   12.691373\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12  220.139999  221.750000  214.910004  216.979996\n",
       " 2025-03-13  215.949997  216.839996  208.419998  209.679993\n",
       " 2025-03-14  211.250000  213.949997  209.580002  213.490005\n",
       " 2025-03-17  213.309998  215.220001  209.970001  214.000000\n",
       " 2025-03-18  214.160004  215.149994  211.490005  212.690002\n",
       " \n",
       " [3321 rows x 4 columns],\n",
       " 'UPS': Price             Open        High         Low       Close\n",
       " Ticker             UPS         UPS         UPS         UPS\n",
       " Date                                                      \n",
       " 2012-01-03   48.284520   48.878206   48.167086   48.382381\n",
       " 2012-01-04   48.232334   48.519394   47.964845   48.173615\n",
       " 2012-01-05   47.925696   47.951793   47.071046   47.703880\n",
       " 2012-01-06   47.710409   48.238861   47.658220   47.938755\n",
       " 2012-01-09   47.788680   47.951781   47.514671   47.919159\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12  115.900002  116.070000  114.949997  115.260002\n",
       " 2025-03-13  115.769997  117.470001  114.959999  115.230003\n",
       " 2025-03-14  115.790001  116.919998  115.089996  116.760002\n",
       " 2025-03-17  117.000000  118.779999  116.919998  118.059998\n",
       " 2025-03-18  118.040001  119.000000  117.860001  118.860001\n",
       " \n",
       " [3321 rows x 4 columns],\n",
       " 'LOW': Price             Open        High         Low       Close\n",
       " Ticker             LOW         LOW         LOW         LOW\n",
       " Date                                                      \n",
       " 2012-01-03   20.236957   20.512987   20.063452   20.126545\n",
       " 2012-01-04   20.126537   20.907308   20.079217   20.875761\n",
       " 2012-01-05   20.789017   20.852109   20.489326   20.796904\n",
       " 2012-01-06   20.789011   20.867875   20.576073   20.773237\n",
       " 2012-01-09   20.804790   20.804790   20.473554   20.583967\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12  233.009995  234.750000  226.399994  228.330002\n",
       " 2025-03-13  227.729996  228.360001  220.169998  222.660004\n",
       " 2025-03-14  224.339996  224.759995  221.020004  224.440002\n",
       " 2025-03-17  225.000000  226.630005  223.399994  225.850006\n",
       " 2025-03-18  224.869995  225.580002  222.570007  222.949997\n",
       " \n",
       " [3321 rows x 4 columns],\n",
       " 'GOOGL': Price             Open        High         Low       Close\n",
       " Ticker           GOOGL       GOOGL       GOOGL       GOOGL\n",
       " Date                                                      \n",
       " 2012-01-03   16.262092   16.640911   16.247896   16.572668\n",
       " 2012-01-04   16.563204   16.693214   16.453370   16.644150\n",
       " 2012-01-05   16.490977   16.536803   16.344031   16.413269\n",
       " 2012-01-06   16.416756   16.437927   16.183636   16.189365\n",
       " 2012-01-09   16.101696   16.114149   15.472323   15.502957\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12  166.580002  167.639999  163.529999  167.110001\n",
       " 2025-03-13  166.039993  166.130005  162.110001  162.759995\n",
       " 2025-03-14  163.270004  166.490005  162.449997  165.490005\n",
       " 2025-03-17  165.029999  166.300003  163.669998  164.289993\n",
       " 2025-03-18  163.679993  164.250000  156.720001  160.669998\n",
       " \n",
       " [3321 rows x 4 columns],\n",
       " 'AMD': Price             Open        High         Low       Close\n",
       " Ticker             AMD         AMD         AMD         AMD\n",
       " Date                                                      \n",
       " 2012-01-03    5.530000    5.590000    5.440000    5.480000\n",
       " 2012-01-04    5.470000    5.490000    5.410000    5.460000\n",
       " 2012-01-05    5.450000    5.570000    5.350000    5.460000\n",
       " 2012-01-06    5.440000    5.520000    5.390000    5.430000\n",
       " 2012-01-09    5.420000    5.600000    5.380000    5.590000\n",
       " ...                ...         ...         ...         ...\n",
       " 2025-03-12   99.050003  101.720001   98.169998  100.790001\n",
       " 2025-03-13   99.720001  100.070000   97.269997   98.110001\n",
       " 2025-03-14   99.639999  101.220001   99.580002  100.970001\n",
       " 2025-03-17  102.599998  106.150002  102.599998  104.589996\n",
       " 2025-03-18  103.849998  104.550003  102.970001  103.510002\n",
       " \n",
       " [3321 rows x 4 columns]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0005a93b-c6da-44ad-baf7-d58269e55351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_scaled = {}\n",
    "\n",
    "for company in df.keys():\n",
    "    df_scaled[company] = pd.DataFrame(scaler.fit_transform(df[company]), columns=df[company].columns, index=df[company].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec452366-853a-41ae-99bb-fa750a0071d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>1.929333</td>\n",
       "      <td>1.966667</td>\n",
       "      <td>1.843333</td>\n",
       "      <td>1.872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>1.880667</td>\n",
       "      <td>1.911333</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.847333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>1.850667</td>\n",
       "      <td>1.862000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>1.808000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>1.813333</td>\n",
       "      <td>1.852667</td>\n",
       "      <td>1.760667</td>\n",
       "      <td>1.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.832667</td>\n",
       "      <td>1.741333</td>\n",
       "      <td>1.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-12</th>\n",
       "      <td>247.220001</td>\n",
       "      <td>251.839996</td>\n",
       "      <td>241.100006</td>\n",
       "      <td>248.089996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-13</th>\n",
       "      <td>248.130005</td>\n",
       "      <td>248.289993</td>\n",
       "      <td>232.600006</td>\n",
       "      <td>240.679993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-14</th>\n",
       "      <td>247.309998</td>\n",
       "      <td>251.580002</td>\n",
       "      <td>240.729996</td>\n",
       "      <td>249.979996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-17</th>\n",
       "      <td>245.059998</td>\n",
       "      <td>245.399994</td>\n",
       "      <td>232.800003</td>\n",
       "      <td>238.009995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-18</th>\n",
       "      <td>228.160004</td>\n",
       "      <td>230.100006</td>\n",
       "      <td>222.279999</td>\n",
       "      <td>225.309998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3321 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price             Open        High         Low       Close\n",
       "Ticker            TSLA        TSLA        TSLA        TSLA\n",
       "Date                                                      \n",
       "2012-01-03    1.929333    1.966667    1.843333    1.872000\n",
       "2012-01-04    1.880667    1.911333    1.833333    1.847333\n",
       "2012-01-05    1.850667    1.862000    1.790000    1.808000\n",
       "2012-01-06    1.813333    1.852667    1.760667    1.794000\n",
       "2012-01-09    1.800000    1.832667    1.741333    1.816667\n",
       "...                ...         ...         ...         ...\n",
       "2025-03-12  247.220001  251.839996  241.100006  248.089996\n",
       "2025-03-13  248.130005  248.289993  232.600006  240.679993\n",
       "2025-03-14  247.309998  251.580002  240.729996  249.979996\n",
       "2025-03-17  245.059998  245.399994  232.800003  238.009995\n",
       "2025-03-18  228.160004  230.100006  222.279999  225.309998\n",
       "\n",
       "[3321 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[main_company]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66becc4e-20af-4672-a6f8-c22ef5940904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Minimum available data points: 3321\n",
      "🔄 Sample 0: X shape = (720,), y = [0.00103544 0.00140789 0.0015066 ]\n",
      "🔄 Sample 1: X shape = (720,), y = [0.00104914 0.00144737 0.00158743]\n",
      "🔄 Sample 2: X shape = (720,), y = [0.00111214 0.00158772 0.00169753]\n",
      "✅ Created dataset: X=(3290, 720), y=(3290, 3)\n",
      "Final X shape: (3290, 720)\n",
      "Final y shape: (3290, 3)\n",
      "✅ Train: X=(2632, 720), y=(2632, 3)\n",
      "✅ Test: X=(658, 720), y=(658, 3)\n"
     ]
    }
   ],
   "source": [
    "def create_correlation_dataset(main_company, correlation, df, time_step=300):\n",
    "    if main_company not in df:\n",
    "        raise ValueError(f\"{main_company} not found in dataset!\")\n",
    "\n",
    "    correlated_companies = correlation.get(main_company, [])\n",
    "    if len(correlated_companies) < 5:\n",
    "        raise ValueError(f\"Not enough correlated companies for {main_company}\")\n",
    "\n",
    "    # ✅ Ensure correlated companies exist\n",
    "    for company in correlated_companies:\n",
    "        if company not in df:\n",
    "            raise ValueError(f\"Correlated company {company} not found in dataset!\")\n",
    "\n",
    "    # ✅ Find the minimum length\n",
    "    min_length = min(len(df[main_company]), *[len(df[comp]) for comp in correlated_companies])\n",
    "    if min_length < time_step + 1:\n",
    "        raise ValueError(f\"Not enough data for {main_company} (needs at least {time_step + 1} rows, found {min_length})\")\n",
    "\n",
    "    print(f\"✅ Minimum available data points: {min_length}\")\n",
    "\n",
    "    dataX, dataY = [], []\n",
    "\n",
    "    for i in range(min_length - time_step - 1):\n",
    "        # ✅ Extract time-step sequences for the main company\n",
    "        x_features = df[main_company].iloc[i:(i + time_step)].values.flatten()\n",
    "\n",
    "        # ✅ Append correlated companies' data\n",
    "        for company in correlated_companies:\n",
    "            correlated_data = df[company].iloc[i:(i + time_step)].values.flatten()\n",
    "            x_features = np.concatenate((x_features, correlated_data))  # ✅ Fix shape issue\n",
    "\n",
    "        # ✅ Append X data properly!\n",
    "        dataX.append(x_features)  # 🚨 FIXED: You forgot to append `x_features`\n",
    "        dataY.append(df[main_company].iloc[i + time_step, [1, 2, 3]].values)  \n",
    "\n",
    "        # 🔍 Print first few samples for debugging\n",
    "        if i < 3:\n",
    "            print(f\"🔄 Sample {i}: X shape = {x_features.shape}, y = {dataY[-1]}\")\n",
    "\n",
    "    X, y = np.array(dataX), np.array(dataY)\n",
    "\n",
    "    print(f\"✅ Created dataset: X={X.shape}, y={y.shape}\")\n",
    "    return X, y\n",
    "\n",
    "# ✅ Generate dataset\n",
    "X, y = create_correlation_dataset(main_company, correlation, df_scaled, time_step=30)\n",
    "\n",
    "# ✅ Check shape before splitting\n",
    "print(\"Final X shape:\", X.shape)  # Should be (samples, features)\n",
    "print(\"Final y shape:\", y.shape)  # Should be (samples, 3)\n",
    "\n",
    "# ✅ Split dataset (Only if X is valid)\n",
    "if X.shape[0] > 0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    print(f\"✅ Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "    print(f\"✅ Test: X={X_test.shape}, y={y_test.shape}\")\n",
    "else:\n",
    "    print(\"🚨 X is empty! Check dataset preprocessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3405721-6597-4a8a-aaef-6c53beb3659f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.26213215e-04, 3.62952421e-04, 7.32455034e-04, ...,\n",
       "        2.54421333e-02, 2.72494058e-02, 2.71739132e-02],\n",
       "       [2.23569467e-04, 2.49271702e-04, 7.10525263e-04, ...,\n",
       "        2.57524040e-02, 2.75398100e-02, 2.70785662e-02],\n",
       "       [1.60295118e-04, 1.47919929e-04, 6.15496778e-04, ...,\n",
       "        2.61956463e-02, 2.73946079e-02, 2.84610984e-02],\n",
       "       ...,\n",
       "       [4.56655630e-01, 4.61304567e-01, 4.61024164e-01, ...,\n",
       "        3.94175797e-01, 4.09854317e-01, 4.20480538e-01],\n",
       "       [4.62202697e-01, 4.80479355e-01, 4.75088464e-01, ...,\n",
       "        4.01267674e-01, 4.20986379e-01, 4.29300134e-01],\n",
       "       [4.66041328e-01, 4.58914572e-01, 4.54350194e-01, ...,\n",
       "        4.12747645e-01, 4.30521258e-01, 4.42648737e-01]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfd82e-942f-479d-ab6f-42502992c45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reshaped for LSTM: X_train=(2632, 30, 24), X_test=(658, 30, 24)\n"
     ]
    }
   ],
   "source": [
    "num_features = X_train.shape[1] // 30  \n",
    "X_train = X_train.reshape(X_train.shape[0], 30, num_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], 30, num_features)\n",
    "\n",
    "print(f\"✅ Reshaped for LSTM: X_train={X_train.shape}, X_test={X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a9fa52f-f21c-480c-9da6-c531e3b0f9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 30, 512)           1099776   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 30, 512)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 128)               328192    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1436419 (5.48 MB)\n",
      "Trainable params: 1436419 (5.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(units=512, return_sequences=True, input_shape=(30, num_features)), \n",
    "    Dropout(0.2),  \n",
    "    LSTM(units=128, return_sequences=False),  \n",
    "    Dropout(0.2),\n",
    "    Dense(units=64, activation='relu'),  \n",
    "    Dense(units=3)  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f9d9caf-08e3-4e93-b1f1-7d701c96fed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - 22s 228ms/step - loss: 0.0049 - mae: 0.0382 - val_loss: 0.0385 - val_mae: 0.1536\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 20s 237ms/step - loss: 0.0021 - mae: 0.0252 - val_loss: 0.0467 - val_mae: 0.1683\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 20s 235ms/step - loss: 0.0022 - mae: 0.0242 - val_loss: 0.0540 - val_mae: 0.1800\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 20s 236ms/step - loss: 0.0017 - mae: 0.0216 - val_loss: 0.0490 - val_mae: 0.1755\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 20s 241ms/step - loss: 0.0023 - mae: 0.0236 - val_loss: 0.0321 - val_mae: 0.1398\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 0.0016 - mae: 0.0204 - val_loss: 0.0454 - val_mae: 0.1703\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 0.0020 - mae: 0.0217 - val_loss: 0.0537 - val_mae: 0.1891\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 20s 246ms/step - loss: 0.0018 - mae: 0.0204 - val_loss: 0.0387 - val_mae: 0.1548\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 21s 256ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 0.0353 - val_mae: 0.1475\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 22s 262ms/step - loss: 0.0015 - mae: 0.0191 - val_loss: 0.0381 - val_mae: 0.1532\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 22s 265ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 0.0485 - val_mae: 0.1791\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 21s 257ms/step - loss: 0.0015 - mae: 0.0186 - val_loss: 0.0395 - val_mae: 0.1575\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 21s 252ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 0.0535 - val_mae: 0.1846\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 21s 254ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 0.0370 - val_mae: 0.1513\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 21s 258ms/step - loss: 0.0013 - mae: 0.0173 - val_loss: 0.0394 - val_mae: 0.1566\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 22s 262ms/step - loss: 0.0016 - mae: 0.0190 - val_loss: 0.0383 - val_mae: 0.1562\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 22s 268ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 0.0439 - val_mae: 0.1683\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 23s 275ms/step - loss: 0.0015 - mae: 0.0185 - val_loss: 0.0496 - val_mae: 0.1788\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 23s 281ms/step - loss: 0.0013 - mae: 0.0175 - val_loss: 0.0432 - val_mae: 0.1673\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 22s 267ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 0.0430 - val_mae: 0.1641\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 21s 259ms/step - loss: 0.0012 - mae: 0.0166 - val_loss: 0.0444 - val_mae: 0.1686\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 23s 279ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 0.0431 - val_mae: 0.1648\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 23s 284ms/step - loss: 0.0011 - mae: 0.0158 - val_loss: 0.0430 - val_mae: 0.1663\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 24s 288ms/step - loss: 0.0013 - mae: 0.0181 - val_loss: 0.0334 - val_mae: 0.1474\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 24s 294ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 0.0367 - val_mae: 0.1533\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 23s 280ms/step - loss: 9.7599e-04 - mae: 0.0153 - val_loss: 0.0345 - val_mae: 0.1475\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 22s 265ms/step - loss: 0.0012 - mae: 0.0164 - val_loss: 0.0409 - val_mae: 0.1628\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 21s 255ms/step - loss: 0.0010 - mae: 0.0154 - val_loss: 0.0373 - val_mae: 0.1539\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 23s 274ms/step - loss: 0.0011 - mae: 0.0161 - val_loss: 0.0449 - val_mae: 0.1677\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 23s 283ms/step - loss: 0.0015 - mae: 0.0189 - val_loss: 0.0517 - val_mae: 0.1832\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 23s 275ms/step - loss: 9.0502e-04 - mae: 0.0150 - val_loss: 0.0547 - val_mae: 0.1842\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 23s 272ms/step - loss: 0.0011 - mae: 0.0162 - val_loss: 0.0432 - val_mae: 0.1633\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 23s 280ms/step - loss: 0.0010 - mae: 0.0160 - val_loss: 0.0477 - val_mae: 0.1733\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 23s 272ms/step - loss: 0.0011 - mae: 0.0163 - val_loss: 0.0547 - val_mae: 0.1861\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 24s 294ms/step - loss: 0.0010 - mae: 0.0157 - val_loss: 0.0438 - val_mae: 0.1653\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 25s 303ms/step - loss: 8.8750e-04 - mae: 0.0143 - val_loss: 0.0428 - val_mae: 0.1612\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 24s 283ms/step - loss: 9.8445e-04 - mae: 0.0152 - val_loss: 0.0556 - val_mae: 0.1836\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 23s 273ms/step - loss: 9.0384e-04 - mae: 0.0147 - val_loss: 0.0484 - val_mae: 0.1726\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 23s 283ms/step - loss: 8.6343e-04 - mae: 0.0143 - val_loss: 0.0421 - val_mae: 0.1619\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 24s 291ms/step - loss: 7.7394e-04 - mae: 0.0140 - val_loss: 0.0391 - val_mae: 0.1568\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 26s 316ms/step - loss: 7.8395e-04 - mae: 0.0138 - val_loss: 0.0344 - val_mae: 0.1534\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 24s 286ms/step - loss: 9.3473e-04 - mae: 0.0149 - val_loss: 0.0430 - val_mae: 0.1633\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 22s 267ms/step - loss: 8.7134e-04 - mae: 0.0142 - val_loss: 0.0552 - val_mae: 0.1915\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 22s 267ms/step - loss: 7.1008e-04 - mae: 0.0130 - val_loss: 0.0431 - val_mae: 0.1604\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 25s 297ms/step - loss: 0.0012 - mae: 0.0161 - val_loss: 0.0486 - val_mae: 0.1772\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 25s 298ms/step - loss: 7.8892e-04 - mae: 0.0140 - val_loss: 0.0364 - val_mae: 0.1536\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 24s 286ms/step - loss: 8.0056e-04 - mae: 0.0137 - val_loss: 0.0369 - val_mae: 0.1548\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 21s 250ms/step - loss: 7.4911e-04 - mae: 0.0137 - val_loss: 0.0493 - val_mae: 0.1812\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 23s 274ms/step - loss: 6.7656e-04 - mae: 0.0135 - val_loss: 0.0384 - val_mae: 0.1643\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 24s 292ms/step - loss: 5.2281e-04 - mae: 0.0115 - val_loss: 0.0399 - val_mae: 0.1629\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 24s 290ms/step - loss: 6.0071e-04 - mae: 0.0120 - val_loss: 0.0490 - val_mae: 0.1746\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 25s 297ms/step - loss: 4.4973e-04 - mae: 0.0109 - val_loss: 0.0462 - val_mae: 0.1789\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 25s 299ms/step - loss: 4.3671e-04 - mae: 0.0107 - val_loss: 0.0524 - val_mae: 0.1912\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 21s 255ms/step - loss: 5.2133e-04 - mae: 0.0115 - val_loss: 0.0412 - val_mae: 0.1681\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 21s 258ms/step - loss: 5.0076e-04 - mae: 0.0111 - val_loss: 0.0368 - val_mae: 0.1567\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 23s 277ms/step - loss: 4.3933e-04 - mae: 0.0106 - val_loss: 0.0380 - val_mae: 0.1585\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 22s 271ms/step - loss: 4.4091e-04 - mae: 0.0105 - val_loss: 0.0356 - val_mae: 0.1561\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 22s 262ms/step - loss: 4.0364e-04 - mae: 0.0101 - val_loss: 0.0449 - val_mae: 0.1760\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 24s 293ms/step - loss: 4.4954e-04 - mae: 0.0111 - val_loss: 0.0405 - val_mae: 0.1635\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 25s 297ms/step - loss: 4.7806e-04 - mae: 0.0107 - val_loss: 0.0450 - val_mae: 0.1722\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 23s 278ms/step - loss: 4.0489e-04 - mae: 0.0101 - val_loss: 0.0401 - val_mae: 0.1655\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 22s 272ms/step - loss: 4.4425e-04 - mae: 0.0105 - val_loss: 0.0404 - val_mae: 0.1678\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 22s 265ms/step - loss: 4.0358e-04 - mae: 0.0102 - val_loss: 0.0405 - val_mae: 0.1677\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 23s 281ms/step - loss: 3.7997e-04 - mae: 0.0099 - val_loss: 0.0387 - val_mae: 0.1607\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 24s 285ms/step - loss: 3.6046e-04 - mae: 0.0093 - val_loss: 0.0397 - val_mae: 0.1652\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 23s 279ms/step - loss: 3.3954e-04 - mae: 0.0098 - val_loss: 0.0359 - val_mae: 0.1469\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 23s 280ms/step - loss: 3.7028e-04 - mae: 0.0095 - val_loss: 0.0387 - val_mae: 0.1615\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 23s 277ms/step - loss: 3.0807e-04 - mae: 0.0088 - val_loss: 0.0429 - val_mae: 0.1698\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 21s 248ms/step - loss: 2.9875e-04 - mae: 0.0086 - val_loss: 0.0425 - val_mae: 0.1697\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 22s 262ms/step - loss: 2.9844e-04 - mae: 0.0088 - val_loss: 0.0405 - val_mae: 0.1627\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 22s 264ms/step - loss: 3.2463e-04 - mae: 0.0090 - val_loss: 0.0350 - val_mae: 0.1506\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 24s 291ms/step - loss: 3.5406e-04 - mae: 0.0095 - val_loss: 0.0416 - val_mae: 0.1715\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 26s 311ms/step - loss: 5.3841e-04 - mae: 0.0120 - val_loss: 0.0345 - val_mae: 0.1453\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 25s 301ms/step - loss: 3.4558e-04 - mae: 0.0095 - val_loss: 0.0417 - val_mae: 0.1625\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 24s 289ms/step - loss: 3.0900e-04 - mae: 0.0094 - val_loss: 0.0428 - val_mae: 0.1693\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 22s 269ms/step - loss: 2.9626e-04 - mae: 0.0085 - val_loss: 0.0363 - val_mae: 0.1492\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 23s 274ms/step - loss: 3.5428e-04 - mae: 0.0092 - val_loss: 0.0466 - val_mae: 0.1784\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 21s 253ms/step - loss: 2.9646e-04 - mae: 0.0087 - val_loss: 0.0350 - val_mae: 0.1491\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 22s 264ms/step - loss: 2.4753e-04 - mae: 0.0081 - val_loss: 0.0433 - val_mae: 0.1687\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 25s 302ms/step - loss: 2.9015e-04 - mae: 0.0083 - val_loss: 0.0399 - val_mae: 0.1602\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 25s 303ms/step - loss: 2.7615e-04 - mae: 0.0084 - val_loss: 0.0386 - val_mae: 0.1608\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 23s 275ms/step - loss: 2.8381e-04 - mae: 0.0085 - val_loss: 0.0454 - val_mae: 0.1727\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 21s 254ms/step - loss: 2.8765e-04 - mae: 0.0087 - val_loss: 0.0326 - val_mae: 0.1454\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 22s 267ms/step - loss: 2.9493e-04 - mae: 0.0089 - val_loss: 0.0332 - val_mae: 0.1439\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 23s 282ms/step - loss: 2.8382e-04 - mae: 0.0083 - val_loss: 0.0410 - val_mae: 0.1600\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 25s 301ms/step - loss: 2.4846e-04 - mae: 0.0079 - val_loss: 0.0409 - val_mae: 0.1612\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 24s 295ms/step - loss: 2.5481e-04 - mae: 0.0080 - val_loss: 0.0354 - val_mae: 0.1510\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 23s 276ms/step - loss: 2.4087e-04 - mae: 0.0082 - val_loss: 0.0446 - val_mae: 0.1679\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 23s 283ms/step - loss: 2.5838e-04 - mae: 0.0079 - val_loss: 0.0387 - val_mae: 0.1603\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 23s 281ms/step - loss: 2.1905e-04 - mae: 0.0078 - val_loss: 0.0393 - val_mae: 0.1561\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 23s 274ms/step - loss: 2.3660e-04 - mae: 0.0081 - val_loss: 0.0362 - val_mae: 0.1557\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 24s 287ms/step - loss: 4.3051e-04 - mae: 0.0102 - val_loss: 0.0368 - val_mae: 0.1522\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 23s 274ms/step - loss: 3.3904e-04 - mae: 0.0093 - val_loss: 0.0386 - val_mae: 0.1569\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 24s 287ms/step - loss: 2.6537e-04 - mae: 0.0083 - val_loss: 0.0401 - val_mae: 0.1593\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 24s 295ms/step - loss: 2.6588e-04 - mae: 0.0087 - val_loss: 0.0377 - val_mae: 0.1544\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 21s 256ms/step - loss: 2.3079e-04 - mae: 0.0079 - val_loss: 0.0338 - val_mae: 0.1454\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 20s 246ms/step - loss: 2.0493e-04 - mae: 0.0074 - val_loss: 0.0366 - val_mae: 0.1507\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 21s 256ms/step - loss: 1.8389e-04 - mae: 0.0069 - val_loss: 0.0373 - val_mae: 0.1514\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 26s 309ms/step - loss: 2.0385e-04 - mae: 0.0074 - val_loss: 0.0477 - val_mae: 0.1756\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 24s 288ms/step - loss: 2.8117e-04 - mae: 0.0086 - val_loss: 0.0421 - val_mae: 0.1637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100, batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "model.save('Correlated_Stocks3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "818e8abb-baf2-4291-b0dc-8b595b16be8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 86ms/step - loss: 0.0421 - mae: 0.1637\n",
      "✅ Test Loss: 0.0421, Test MAE: 0.1637\n",
      "21/21 [==============================] - 3s 104ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model = load_model(\"Correlated_Stocks3.h5\")\n",
    "\n",
    "test_loss, test_mae = best_model.evaluate(X_test, y_test)\n",
    "print(f\"✅ Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c694012-94de-4c05-ae44-df6b216fae8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
